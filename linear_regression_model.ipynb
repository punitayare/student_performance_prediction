{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2444c162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded: (9994, 23)\n",
      "Numeric features: ['Date Key', 'Customer ID', 'Quantity', 'Discount', 'Profit', 'Year', 'Month', 'Day', 'Weekday']\n",
      "Categorical features: ['Contact Name', 'Country', 'City', 'Region', 'Subregion', 'Customer', 'Industry', 'Segment', 'Product']\n",
      "Train/Test split: (7995, 18) (1999, 18)\n",
      "LinearRegression: RMSE=521.6896 | MAE=245.5658 | R2=0.2065\n",
      "ElasticNet: RMSE=522.4722 | MAE=225.1916 | R2=0.2041\n",
      "SVR: RMSE=604.1409 | MAE=198.5013 | R2=-0.0641\n",
      "RandomForest: RMSE=238.9629 | MAE=80.5812 | R2=0.8335\n",
      "GradientBoosting: RMSE=243.7621 | MAE=98.9834 | R2=0.8268\n",
      "\n",
      "üèÜ Best model: RandomForest\n",
      "              Model         MAE        RMSE        R2\n",
      "3      RandomForest   80.581223  238.962945  0.833515\n",
      "4  GradientBoosting   98.983444  243.762088  0.826761\n",
      "0  LinearRegression  245.565849  521.689603  0.206515\n",
      "1        ElasticNet  225.191601  522.472207  0.204133\n",
      "2               SVR  198.501347  604.140905 -0.064121\n",
      "üíæ Saved best model ‚Üí best_sales_model.pkl\n",
      "üìÑ Saved predictions sample ‚Üí sample_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ---------------- LOAD DATA ----------------\n",
    "df = pd.read_csv(\"../data_clean/saas_sales_clean.csv\")\n",
    "print(\"‚úÖ Data loaded:\", df.shape)\n",
    "\n",
    "# ---------------- CLEAN & FEATURE PREP ----------------\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], errors='coerce')\n",
    "df = df.dropna(subset=['Sales'])\n",
    "df['Sales'] = pd.to_numeric(df['Sales'], errors='coerce')\n",
    "\n",
    "# Time-based features\n",
    "df['Year'] = df['Order Date'].dt.year\n",
    "df['Month'] = df['Order Date'].dt.month\n",
    "df['Day'] = df['Order Date'].dt.day\n",
    "df['Weekday'] = df['Order Date'].dt.weekday\n",
    "\n",
    "# Drop identifiers and irrelevant columns\n",
    "drop_cols = ['Order ID', 'License', 'Order Date', 'Month_Year']\n",
    "X = df.drop(columns=drop_cols + ['Sales'], errors='ignore')\n",
    "y = df['Sales']\n",
    "\n",
    "# ---------------- FEATURE TYPES ----------------\n",
    "numeric_feats = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_feats = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "print(\"Numeric features:\", numeric_feats)\n",
    "print(\"Categorical features:\", cat_feats)\n",
    "\n",
    "# ---------------- PREPROCESSING ----------------\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='MISSING')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_feats),\n",
    "    ('cat', categorical_transformer, cat_feats)\n",
    "])\n",
    "\n",
    "# ---------------- MODELS ----------------\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"ElasticNet\": ElasticNet(random_state=42),\n",
    "    \"SVR\": SVR(),\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# ---------------- SPLIT ----------------\n",
    "df = df.sort_values(by=\"Order Date\")\n",
    "split = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "print(\"Train/Test split:\", X_train.shape, X_test.shape)\n",
    "\n",
    "# ---------------- TRAIN AND EVALUATE ----------------\n",
    "results = []\n",
    "fitted_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([('pre', preprocessor), ('model', model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    rmse = math.sqrt(mean_squared_error(y_test, preds))\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    results.append({\"Model\": name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2})\n",
    "    fitted_models[name] = pipe\n",
    "    print(f\"{name}: RMSE={rmse:.4f} | MAE={mae:.4f} | R2={r2:.4f}\")\n",
    "\n",
    "# ---------------- BEST MODEL ----------------\n",
    "res_df = pd.DataFrame(results).sort_values(by=\"RMSE\")\n",
    "best_name = res_df.iloc[0][\"Model\"]\n",
    "best_model = fitted_models[best_name]\n",
    "\n",
    "print(\"\\nüèÜ Best model:\", best_name)\n",
    "print(res_df)\n",
    "\n",
    "# ---------------- SAVE MODEL ----------------\n",
    "with open(\"best_sales_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(\"üíæ Saved best model ‚Üí best_sales_model.pkl\")\n",
    "\n",
    "# ---------------- SAMPLE PREDICTIONS ----------------\n",
    "preds = best_model.predict(X_test)\n",
    "sample = pd.DataFrame({\"Actual\": y_test, \"Predicted\": preds})\n",
    "sample.to_csv(\"sample_predictions.csv\", index=False)\n",
    "print(\"üìÑ Saved predictions sample ‚Üí sample_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8b117e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded: (9994, 23)\n",
      "Numeric features: ['Date Key', 'Customer ID', 'Quantity', 'Discount', 'Profit', 'Year', 'Month', 'Day', 'Weekday', 'Profit_Margin', 'Sales_per_Quantity', 'Is_Weekend']\n",
      "Categorical features: ['Contact Name', 'Country', 'City', 'Region', 'Subregion', 'Customer', 'Industry', 'Segment', 'Product']\n",
      "Train/Test split: (7995, 21) (1999, 21)\n",
      "RandomForest: RMSE=153.6565 | MAE=11.0873 | R2=0.9312\n",
      "GradientBoosting: RMSE=74.7911 | MAE=13.0117 | R2=0.9837\n",
      "XGBoost: RMSE=139.6858 | MAE=14.4862 | R2=0.9431\n",
      "\n",
      "üèÜ Best base model: GradientBoosting\n",
      "                        MAE        RMSE        R2\n",
      "RandomForest      11.087295  153.656459  0.931164\n",
      "GradientBoosting  13.011734   74.791115  0.983691\n",
      "XGBoost           14.486191  139.685812  0.943112\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "\n",
      "üéØ Tuned Model Performance:\n",
      "RMSE=140.3077 | MAE=10.0780 | R2=0.9426\n",
      "üíæ Saved tuned model ‚Üí enhanced_best_sales_model.pkl\n",
      "üìÑ Saved predictions sample ‚Üí enhanced_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ---------------- LOAD DATA ----------------\n",
    "df = pd.read_csv(\"../data_clean/saas_sales_clean.csv\")\n",
    "print(\"‚úÖ Data loaded:\", df.shape)\n",
    "\n",
    "# ---------------- BASIC CLEANING ----------------\n",
    "df[\"Order Date\"] = pd.to_datetime(df[\"Order Date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"Sales\"])\n",
    "df[\"Sales\"] = pd.to_numeric(df[\"Sales\"], errors=\"coerce\")\n",
    "\n",
    "# ---------------- FEATURE ENGINEERING ----------------\n",
    "df[\"Year\"] = df[\"Order Date\"].dt.year\n",
    "df[\"Month\"] = df[\"Order Date\"].dt.month\n",
    "df[\"Day\"] = df[\"Order Date\"].dt.day\n",
    "df[\"Weekday\"] = df[\"Order Date\"].dt.weekday\n",
    "\n",
    "# Extra features\n",
    "df[\"Profit_Margin\"] = df[\"Profit\"] / (df[\"Sales\"] + 1e-6)\n",
    "df[\"Sales_per_Quantity\"] = df[\"Sales\"] / (df[\"Quantity\"] + 1e-6)\n",
    "df[\"Is_Weekend\"] = df[\"Weekday\"].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "drop_cols = [\"Order ID\", \"License\", \"Order Date\", \"Month_Year\"]\n",
    "df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# ---------------- DEFINE FEATURES ----------------\n",
    "X = df.drop(columns=[\"Sales\"])\n",
    "y = np.log1p(df[\"Sales\"])  # log transform target\n",
    "\n",
    "numeric_feats = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_feats = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Numeric features:\", numeric_feats)\n",
    "print(\"Categorical features:\", cat_feats)\n",
    "\n",
    "# ---------------- PREPROCESSING ----------------\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"MISSING\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_feats),\n",
    "    (\"cat\", categorical_transformer, cat_feats)\n",
    "])\n",
    "\n",
    "# ---------------- BASE MODELS ----------------\n",
    "base_models = {\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, n_jobs=-1, verbosity=0)\n",
    "}\n",
    "\n",
    "# ---------------- TRAIN TEST SPLIT ----------------\n",
    "df = df.sort_values(by=\"Year\")\n",
    "split = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "print(\"Train/Test split:\", X_train.shape, X_test.shape)\n",
    "\n",
    "# ---------------- TRAIN BASE MODELS ----------------\n",
    "results = {}\n",
    "for name, model in base_models.items():\n",
    "    pipe = Pipeline([(\"pre\", preprocessor), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = np.expm1(pipe.predict(X_test))  # inverse log transform\n",
    "    actuals = np.expm1(y_test)\n",
    "    mae = mean_absolute_error(actuals, preds)\n",
    "    rmse = math.sqrt(mean_squared_error(actuals, preds))\n",
    "    r2 = r2_score(actuals, preds)\n",
    "    results[name] = {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "    print(f\"{name}: RMSE={rmse:.4f} | MAE={mae:.4f} | R2={r2:.4f}\")\n",
    "\n",
    "# ---------------- CHOOSE BEST MODEL ----------------\n",
    "best_name = max(results, key=lambda k: results[k][\"R2\"])\n",
    "print(\"\\nüèÜ Best base model:\", best_name)\n",
    "print(pd.DataFrame(results).T)\n",
    "\n",
    "# ---------------- HYPERPARAMETER TUNING ----------------\n",
    "if best_name == \"XGBoost\":\n",
    "    model = XGBRegressor(random_state=42, n_jobs=-1, verbosity=0)\n",
    "    param_dist = {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [3, 5, 7, 9],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"subsample\": [0.6, 0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "        \"min_child_weight\": [1, 3, 5]\n",
    "    }\n",
    "elif best_name == \"RandomForest\":\n",
    "    model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "    param_dist = {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [10, 20, None],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    }\n",
    "else:  # GradientBoosting\n",
    "    model = GradientBoostingRegressor(random_state=42)\n",
    "    param_dist = {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"max_depth\": [3, 5, 7]\n",
    "    }\n",
    "\n",
    "pipe = Pipeline([(\"pre\", preprocessor), (\"model\", model)])\n",
    "search = RandomizedSearchCV(\n",
    "    pipe, param_distributions={\"model__\" + k: v for k, v in param_dist.items()},\n",
    "    n_iter=10, cv=3, scoring=\"r2\", random_state=42, verbose=1, n_jobs=-1\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "best_model = search.best_estimator_\n",
    "\n",
    "# ---------------- FINAL EVALUATION ----------------\n",
    "preds = np.expm1(best_model.predict(X_test))\n",
    "actuals = np.expm1(y_test)\n",
    "mae = mean_absolute_error(actuals, preds)\n",
    "rmse = math.sqrt(mean_squared_error(actuals, preds))\n",
    "r2 = r2_score(actuals, preds)\n",
    "\n",
    "print(\"\\nüéØ Tuned Model Performance:\")\n",
    "print(f\"RMSE={rmse:.4f} | MAE={mae:.4f} | R2={r2:.4f}\")\n",
    "\n",
    "# ---------------- SAVE MODEL ----------------\n",
    "with open(\"enhanced_best_sales_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(\"üíæ Saved tuned model ‚Üí enhanced_best_sales_model.pkl\")\n",
    "\n",
    "# ---------------- SAVE SAMPLE PREDICTIONS ----------------\n",
    "sample = pd.DataFrame({\"Actual\": actuals, \"Predicted\": preds})\n",
    "sample.to_csv(\"enhanced_predictions.csv\", index=False)\n",
    "print(\"üìÑ Saved predictions sample ‚Üí enhanced_predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
